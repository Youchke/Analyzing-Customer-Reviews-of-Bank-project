import chromedriver_autoinstaller
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
from bs4 import BeautifulSoup
from pathlib import Path
import time
import json
import sys
import io
import re
import random
import os
from datetime import datetime, timedelta
import logging
import traceback

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ChromeDriverManager:
    """Gestionnaire robuste du driver Chrome avec r√©cup√©ration automatique"""
    
    def __init__(self, max_retries=3):
        self.driver = None
        self.max_retries = max_retries
        self.retry_count = 0
        
    def create_driver(self):
        """Cr√©e une nouvelle instance du driver Chrome"""
        try:
            chromedriver_autoinstaller.install()
            
            options = webdriver.ChromeOptions()
            
            # Options de base pour la stabilit√©
            options.add_argument("--no-sandbox")
            options.add_argument("--disable-dev-shm-usage")
            options.add_argument("--disable-gpu")
            options.add_argument("--window-size=1280,720")  # Taille r√©duite
            
            # Options pour √©viter les crashes
            options.add_argument("--disable-extensions")
            options.add_argument("--disable-plugins")
            options.add_argument("--disable-images")
            options.add_argument("--disable-javascript")  # D√©sactiver JS non essentiel
            options.add_argument("--disable-web-security")
            options.add_argument("--disable-features=VizDisplayCompositor")
            
            # Gestion m√©moire am√©lior√©e
            options.add_argument("--memory-pressure-off")
            options.add_argument("--max_old_space_size=4096")
            options.add_argument("--disable-background-timer-throttling")
            options.add_argument("--disable-renderer-backgrounding")
            options.add_argument("--disable-backgrounding-occluded-windows")
            
            # Mode headless pour √©conomiser les ressources (optionnel)
            # options.add_argument("--headless")
            
            # User agent
            options.add_argument("--user-agent=Mozilla/5.0 (Linux; Ubuntu 20.04) AppleWebKit/537.36 Chrome/120.0.0.0")
            
            # Anti-d√©tection
            options.add_argument("--disable-blink-features=AutomationControlled")
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option('useAutomationExtension', False)
            
            driver = webdriver.Chrome(options=options)
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            # Timeouts plus courts pour √©viter les blocages
            driver.set_page_load_timeout(30)
            driver.implicitly_wait(10)
            
            logger.info("‚úÖ Nouveau driver Chrome cr√©√© avec succ√®s")
            return driver
            
        except Exception as e:
            logger.error(f"‚ùå Erreur cr√©ation driver: {e}")
            return None
    
    def get_driver(self):
        """R√©cup√®re le driver actuel ou en cr√©e un nouveau"""
        if self.driver is None:
            self.driver = self.create_driver()
        return self.driver
    
    def is_driver_alive(self):
        """V√©rifie si le driver est encore fonctionnel"""
        try:
            if self.driver is None:
                return False
            # Test simple pour v√©rifier si le driver r√©pond
            self.driver.current_url
            return True
        except:
            return False
    
    def restart_driver(self):
        """Red√©marre le driver en cas de crash"""
        logger.warning("üîÑ Red√©marrage du driver suite √† un crash...")
        
        # Fermer l'ancien driver
        try:
            if self.driver:
                self.driver.quit()
        except:
            pass
        
        self.driver = None
        time.sleep(5)  
        
        # Cr√©er nouveau driver
        self.driver = self.create_driver()
        return self.driver is not None
    
    def execute_with_retry(self, func, *args, **kwargs):
        """Ex√©cute une fonction avec retry automatique en cas de crash"""
        for attempt in range(self.max_retries):
            try:
                if not self.is_driver_alive():
                    if not self.restart_driver():
                        logger.error("‚ùå Impossible de red√©marrer le driver")
                        return None
                
                return func(self.driver, *args, **kwargs)
                
            except WebDriverException as e:
                if "tab crashed" in str(e) or "chrome not reachable" in str(e):
                    logger.warning(f"‚ö† Crash d√©tect√© (tentative {attempt + 1}/{self.max_retries}): {e}")
                    if attempt < self.max_retries - 1:
                        if self.restart_driver():
                            continue
                    else:
                        logger.error("‚ùå √âchec apr√®s toutes les tentatives de r√©cup√©ration")
                        return None
                else:
                    logger.error(f"‚ùå Erreur WebDriver: {e}")
                    return None
            except Exception as e:
                logger.error(f"‚ùå Erreur inattendue: {e}")
                return None
        
        return None
    
    def quit(self):
        """Ferme proprement le driver"""
        try:
            if self.driver:
                self.driver.quit()
                self.driver = None
                logger.info("‚úÖ Driver ferm√© proprement")
        except:
            logger.warning("‚ö† Erreur lors de la fermeture du driver")

def parse_relative_date(relative_str):
    """Parse une date relative en fran√ßais vers format ISO"""
    if not relative_str:
        return None
        
    today = datetime.today()
    relative_str = relative_str.lower().strip()
    
    # Nettoyer la cha√Æne
    relative_str = relative_str.replace(',', '').replace('.', '')
    
    # Patterns pour diff√©rents formats fran√ßais
    patterns = [
        r"il y a (\d+)\s*(jour|jours|mois|semaine|semaines|an|ans|ann√©e|ann√©es)",
        r"il y a (une?|un)\s*(semaine|mois|an|ann√©e)",
        r"(\d+)\s*(jour|jours|mois|semaine|semaines|an|ans|ann√©e|ann√©es)",
        r"(une?|un)\s*(semaine|mois|an|ann√©e)",
        r"(hier|aujourd'hui|today|yesterday)"
    ]
    
    for pattern in patterns:
        match = re.search(pattern, relative_str)
        if match:
            if len(match.groups()) == 1:
                special = match.group(1)
                if special in ['hier', 'yesterday']:
                    result = today - timedelta(days=1)
                elif special in ['aujourd\'hui', 'today']:
                    result = today
                else:
                    continue
            else:
                quantity_str = match.group(1)
                unit = match.group(2)
                
                if quantity_str in ['un', 'une', 'a']:
                    quantity = 1
                else:
                    try:
                        quantity = int(quantity_str)
                    except ValueError:
                        continue
                
                if unit.startswith('jour'):
                    result = today - timedelta(days=quantity)
                elif unit.startswith('semaine'):
                    result = today - timedelta(weeks=quantity)
                elif unit.startswith('mois'):
                    result = today - timedelta(days=30 * quantity)
                elif unit.startswith('an') or unit.startswith('ann√©e'):
                    result = today - timedelta(days=365 * quantity)
                else:
                    continue
            
            return result.strftime('%Y-%m-%d')
    
    return None

def safe_get_page(driver, url, max_wait=30):
    """Charge une page de mani√®re s√©curis√©e avec timeout"""
    try:
        logger.info(f"üìÑ Chargement: {url}")
        driver.get(url)
        
        # Attendre que la page soit charg√©e
        WebDriverWait(driver, max_wait).until(
            lambda d: d.execute_script("return document.readyState") == "complete"
        )
        
        time.sleep(random.uniform(3.0, 5.0))
        return True
        
    except TimeoutException:
        logger.warning(f"‚ö† Timeout lors du chargement de {url}")
        return False
    except Exception as e:
        logger.error(f"‚ùå Erreur chargement page: {e}")
        return False

def extract_branch_links_safe(driver, bank, city):
    """Version s√©curis√©e de l'extraction des liens d'agences"""
    try:
        logger.info(f"üîç Recherche: {bank} √† {city}")
        
        search_query = f"{bank} agence {city} Maroc"
        search_url = f"https://www.google.com/maps/search/{search_query.replace(' ', '+')}"
        
        if not safe_get_page(driver, search_url):
            return []
        
        # Attendre les r√©sultats avec timeout r√©duit
        try:
            wait = WebDriverWait(driver, 15)
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div[role='main']")))
        except TimeoutException:
            logger.warning(f"‚ö† Timeout r√©sultats pour {bank} √† {city}")
            return []
        
        # Scroll limit√© pour √©viter les crashes
        for scroll in range(5):  # R√©duire le nombre de scrolls
            try:
                driver.execute_script("window.scrollBy(0, 1000);")
                time.sleep(2)
            except:
                break
        
        # Extraction des liens
        branch_links = []
        try:
            elements = driver.find_elements(By.CSS_SELECTOR, "a[href*='/maps/place/']")
            for element in elements[:5]:  # Limiter √† 5 liens max par recherche
                href = element.get_attribute("href")
                if href and href not in branch_links:
                    branch_links.append(href)
        except Exception as e:
            logger.warning(f"‚ö† Erreur extraction liens: {e}")
        
        logger.info(f"‚úÖ {len(branch_links)} agences trouv√©es pour {bank} √† {city}")
        return branch_links
        
    except Exception as e:
        logger.error(f"‚ùå Erreur recherche {bank} √† {city}: {e}")
        return []

def extract_reviews_from_branch_safe(driver, branch_url, bank_name, city):
    """Version s√©curis√©e de l'extraction des avis"""
    try:
        logger.info(f"üìñ Extraction avis: {branch_url}")
        
        if not safe_get_page(driver, branch_url):
            return []
        
        # Parser le HTML actuel
        html_content = driver.page_source
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Informations de base de l'agence
        display_name = bank_name
        name_element = soup.select_one('h1.DUwDvf.lfPIob, h1')
        if name_element:
            display_name = name_element.get_text().strip()
        
        location = f"{city} - Localisation inconnue"
        location_element = soup.select_one('div.Io6YTe.fontBodyMedium.kR99db.fdkmkc, [data-item-id="address"]')
        if location_element:
            location = location_element.get_text().strip()
        
        overall_rating = None
        rating_element = soup.select_one('div.F7nice span span, .ceNzKf')
        if rating_element:
            overall_rating = rating_element.get_text().strip()
        
        # Chercher et cliquer sur le bouton des avis
        reviews_clicked = False
        try:
            # M√©thodes simplifi√©es pour trouver le bouton
            button_selectors = [
                "button[aria-label*='avis']",
                "button[data-value='reviews']",
                "*[jsaction*='pane.rating']"
            ]
            
            for selector in button_selectors:
                try:
                    button = driver.find_element(By.CSS_SELECTOR, selector)
                    if button.is_displayed():
                        driver.execute_script("arguments[0].click();", button)
                        reviews_clicked = True
                        logger.info("‚úÖ Bouton avis cliqu√©")
                        break
                except:
                    continue
        except:
            pass
        
        if reviews_clicked:
            time.sleep(5)  # Attendre le chargement des avis
            
            # Scroll limit√© dans les avis
            try:
                for _ in range(3):  # Scroll limit√©
                    driver.execute_script("window.scrollBy(0, 500);")
                    time.sleep(2)
            except:
                pass
        
        # Re-parser apr√®s les actions
        html_content = driver.page_source
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Extraction simplifi√©e des avis
        reviews = []
        review_elements = soup.select('div.jftiEf.fontBodyMedium, div[data-review-id]')
        
        for i, review_element in enumerate(review_elements[:10]):  # Limiter √† 10 avis
            try:
                # Date
                date_element = review_element.select_one('span.rsqaWe, .DU9Pgb')
                review_date = None
                if date_element:
                    review_date = parse_relative_date(date_element.get_text().strip())
                
                # Texte
                text_element = review_element.select_one('span.wiI7pd, .MyEned')
                review_text = None
                if text_element:
                    review_text = text_element.get_text().strip()
                
                # Rating (nombre d'√©toiles)
                stars = review_element.select('span.elGi1d')
                review_rating = len(stars) if stars else None
                
                if review_text or review_rating:  # Au moins un √©l√©ment doit √™tre pr√©sent
                    reviews.append({
                        "bank_name": display_name,
                        "branch_name": f"{display_name} - {location}",
                        "bank_rating": overall_rating,
                        "bank_location": location,
                        "review_date": review_date,
                        "review_text": review_text,
                        "review_rating": review_rating
                    })
                
            except Exception as e:
                logger.warning(f"‚ö† Erreur avis {i+1}: {e}")
                continue
        
        logger.info(f"‚úÖ {len(reviews)} avis extraits")
        return reviews
        
    except Exception as e:
        logger.error(f"‚ùå Erreur extraction avis: {e}")
        return []

def extract():
    """Fonction principale avec gestion robuste des crashes"""
    cities = [
        "Agadir", "Casablanca", "Rabat", "Tanger", 
        "Marrakech", "Kenitra", "Tata"
    ]

    banks = [
        "Attijariwafa Bank", "AL BARID BANK", "BANQUE POPULAIRE",
        "BANK OF AFRICA", "BMCI BANK", "CIH BANK"
    ]
    
    # Configuration des fichiers
    output_dir = Path('/home/younes/airflow/data')
    output_dir.mkdir(parents=True, exist_ok=True)
    file_path = output_dir / 'all_reviews2.json'
    
    if file_path.exists():
        file_path.unlink()
    
    # Initialiser le gestionnaire de driver
    driver_manager = ChromeDriverManager(max_retries=3)
    all_reviews = []
    
    try:
        logger.info("üöÄ D√©but de l'extraction avec gestion anti-crash")
        
        for city in cities:
            logger.info(f"\n{'='*60}")
            logger.info(f"üåç VILLE: {city}")
            logger.info(f"{'='*60}")
            
            for bank in banks:
                logger.info(f"\nüè¶ {bank} √† {city}")
                
                # Extraction des liens avec retry automatique
                branch_links = driver_manager.execute_with_retry(
                    extract_branch_links_safe, bank, city
                )
                
                if not branch_links:
                    logger.warning(f"‚ö† Aucune agence pour {bank} √† {city}")
                    continue
                
                # Traiter chaque agence (limit√© √† 2 pour √©viter les crashes)
                for i, branch_url in enumerate(branch_links[:2]):
                    logger.info(f"--- Agence {i+1}/{len(branch_links[:2])} ---")
                    
                    reviews = driver_manager.execute_with_retry(
                        extract_reviews_from_branch_safe, branch_url, bank, city
                    )
                    
                    if reviews:
                        all_reviews.extend(reviews)
                        
                        # Sauvegarde incr√©mentale
                        with open(file_path, 'w', encoding='utf-8') as f:
                            json.dump(all_reviews, f, indent=2, ensure_ascii=False)
                        
                        logger.info(f"‚úÖ +{len(reviews)} avis (Total: {len(all_reviews)})")
                    
                    # Pause entre agences
                    time.sleep(random.uniform(8.0, 12.0))
                
                # Pause entre banques
                time.sleep(random.uniform(10.0, 15.0))
            
            logger.info(f"‚úÖ VILLE {city} TERMIN√âE - Total: {len(all_reviews)} avis")
        
        # Statistiques finales
        total_with_text = sum(1 for r in all_reviews if r.get('review_text'))
        logger.info(f"üéâ EXTRACTION TERMIN√âE!")
        logger.info(f"üìä Total: {len(all_reviews)} avis ({total_with_text} avec texte)")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur critique: {e}")
        traceback.print_exc()
        
    finally:
        # Fermeture propre
        driver_manager.quit()
        
        # Sauvegarde finale
        if all_reviews:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(all_reviews, f, indent=2, ensure_ascii=False)
            logger.info(f"üíæ Donn√©es sauvegard√©es: {file_path}")

# if __name__ == "__main__":
#     extract()